{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcb9bd5-3ec1-4531-bd71-c691912d2890",
   "metadata": {},
   "source": [
    "## YaTC embeddings calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a539b0d-9f20-42da-8e36-f85ba9b84d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kell/demystifying/YaTC/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../models/YaTC/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eff50ee-b863-4567-a645-0a7ed7e193bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bf0219-6d2e-441f-9367-7ceb30b412c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import threading\n",
    "\n",
    "from finetune import build_dataset\n",
    "import torch\n",
    "import models_YaTC\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccd2ea-44a3-4062-a17c-c1d6e8881e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(datafolder, n_classes, batch_size=64, limit = 10**30, gpus=4):\n",
    "    loader_yatc = lambda: True\n",
    "    loader_yatc.data_path = datafolder\n",
    "    loader_yatc = build_dataset(is_train=True, args=loader_yatc)\n",
    "    loader_yatc = torch.utils.data.DataLoader(\n",
    "            loader_yatc, sampler=torch.utils.data.SequentialSampler(loader_yatc),\n",
    "            batch_size=batch_size,\n",
    "            num_workers=4,\n",
    "            pin_memory=False,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    checkpoint_model = torch.load(\"../models/YaTC/YaTC_pretrained_model.pth\")['model']\n",
    "    # yes without the 's'\n",
    "    yatc_frozen_model = models_YaTC.__dict__['TraFormer_YaTC'](\n",
    "            num_classes=n_classes,\n",
    "            drop_path_rate=0.1,\n",
    "        )\n",
    "    interpolate_pos_embed(yatc_frozen_model, checkpoint_model)\n",
    "\n",
    "    #rename norm to fc_norm and delete extra keys\n",
    "    checkpoint_model['fc_norm.bias'] = checkpoint_model['norm.bias']\n",
    "    checkpoint_model['fc_norm.weight'] = checkpoint_model['norm.weight']\n",
    "\n",
    "    keys_to_del = ['mask_token', 'norm.weight', 'norm.bias']\n",
    "    for key in checkpoint_model.keys():\n",
    "        if key.startswith('decoder'):\n",
    "            keys_to_del.append(key)\n",
    "\n",
    "    for key in keys_to_del:\n",
    "        del checkpoint_model[key]\n",
    "\n",
    "    yatc_frozen_model.load_state_dict(checkpoint_model, strict=False)\n",
    "\n",
    "    yatc_models = {}\n",
    "    for i in range(gpus):\n",
    "        yatc_models[i] = copy.deepcopy(yatc_frozen_model)\n",
    "        yatc_models[i].to(f\"cuda:{i}\")\n",
    "\n",
    "    print(f\"Total: {len(loader_yatc)}\")\n",
    "\n",
    "    def encode_and_append(batch, model, result_list, i):\n",
    "        imgs, _ = batch\n",
    "        imgs = imgs.to(f\"cuda:{i}\")\n",
    "        with torch.no_grad():\n",
    "            result_list.append(model.forward_features(imgs).mean(dim=1).cpu())\n",
    "        del imgs\n",
    "        del batch\n",
    "\n",
    "    counter = 0\n",
    "    result_embeddings = []\n",
    "    result_filenames = []\n",
    "    with torch.no_grad():\n",
    "        iterator = iter(loader_yatc)\n",
    "        try:\n",
    "            for y in tqdm(range(0, min(len(loader_yatc) // gpus, limit))):\n",
    "                yatc_emb = defaultdict(list)\n",
    "                batches = [next(iterator) for i in range(gpus)]\n",
    "                threads = []\n",
    "                for i in range(gpus):\n",
    "                    t = threading.Thread(target=encode_and_append, args=(batches[i], yatc_models[i], yatc_emb[i], i))\n",
    "                    t.start()\n",
    "                    threads.append(t)\n",
    "                for t in threads:\n",
    "                    t.join()\n",
    "                del batches\n",
    "                result_embeddings.append(torch.cat([torch.cat(yatc_emb[i]) for i in yatc_emb]))\n",
    "                result_filenames.extend([x[0] for x in loader_yatc.dataset.samples[y*gpus*batch_size:(y+1)*gpus*batch_size]])\n",
    "                \n",
    "        except StopIteration:\n",
    "            print(\"finished\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return torch.cat(result_embeddings), result_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02f277-bebd-4e85-b9b4-e6ebfbdcdae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 367\n",
      "    Root location: /pscratch/sd/k/kell/demystifying/data/newYaTC/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367/367 [00:06<00:00, 60.23it/s]\n"
     ]
    }
   ],
   "source": [
    "caida_emb = get_embeddings(\"../data/newYaTC/\", n_classes=4, batch_size=1, gpus=1)\n",
    "with open(\"../data/newYaTC/synth_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(caida_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68a4fe-932f-4d0f-8e4b-facd4e369be2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dev/shm/data/caida/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m caida_emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/dev/shm/data/caida/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/dev/shm/data/caida_emb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(caida_emb, f)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(datafolder, n_classes, batch_size, limit, gpus)\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_yatc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m loader_yatc\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m=\u001b[39m datafolder\n\u001b[0;32m----> 4\u001b[0m loader_yatc \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_yatc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m loader_yatc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m      6\u001b[0m         loader_yatc, sampler\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSequentialSampler(loader_yatc),\n\u001b[1;32m      7\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m checkpoint_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/global/homes/k/kell/scratch/demystifying/YaTC/YaTC_pretrained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/YaTC/src/finetune.py:159\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[0;34m(is_train, args)\u001b[0m\n\u001b[1;32m    153\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    154\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mGrayscale(num_output_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    155\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m    156\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean, std),\n\u001b[1;32m    157\u001b[0m ])\n\u001b[1;32m    158\u001b[0m root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mdata_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 159\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torchvision-0.14.1a0+5e8e2f1-py3.9-linux-x86_64.egg/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torchvision-0.14.1a0+5e8e2f1-py3.9-linux-x86_64.egg/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torchvision-0.14.1a0+5e8e2f1-py3.9-linux-x86_64.egg/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torchvision-0.14.1a0+5e8e2f1-py3.9-linux-x86_64.egg/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dev/shm/data/caida/train'"
     ]
    }
   ],
   "source": [
    "caida_emb = get_embeddings(\"../data/caida/\", n_classes=1, batch_size=512)\n",
    "with open(\"../data/caida_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(caida_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a7e21-be61-4db2-90b2-5ed0680ad79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1578213\n",
      "    Root location: /dev/shm/data/cicapt/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa5f6fdf700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa5f6fdf700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fa5f6fdf700>: \n",
      "can only test a child processTraceback (most recent call last):\n",
      "\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7fa5f6fdf700>\n",
      "\n",
      "AssertionError: can only test a child processTraceback (most recent call last):\n",
      "\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/global/common/software/m4629/environments/condaenv/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|██████████| 770/770 [01:56<00:00,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "caida_emb = get_embeddings(\"../data/cicapt/\", n_classes=22, batch_size=512)\n",
    "with open(\"../data/cicapt_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(caida_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e120e-cc23-4fe7-8bee-bdf6adc806c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 558884\n",
      "    Root location: /dev/shm/data/cicids/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:41<00:00,  6.49it/s]\n"
     ]
    }
   ],
   "source": [
    "cicids_emb = get_embeddings(\"../data/cicids/\", n_classes=8, batch_size=512)\n",
    "with open(\"../data/cicids_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(cicids_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f56728-3d11-4b94-8ef8-bc0ecca85503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 44647\n",
      "    Root location: /dev/shm/data/cross/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "cross_emb = get_embeddings(\"../data/cross/\", n_classes=210, batch_size=512)\n",
    "with open(\"../data/cross_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(cross_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231dfd38-b49c-4c78-ac56-540ad7f0550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 999954\n",
      "    Root location: /dev/shm/data/mawi/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [01:12<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "mawi_emb = get_embeddings(\"../data/mawi/\", n_classes=1, batch_size=512)\n",
    "with open(\"../data/mawi_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(mawi_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e801c-28e2-4fa3-bda2-e3f232b29145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 10\n",
      "    Root location: /dev/shm/data/yatc/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 55.54it/s]\n"
     ]
    }
   ],
   "source": [
    "emb = get_embeddings(\"../data/yatc/\", n_classes=1, batch_size=1, gpus=1)\n",
    "with open(\"../data/synthstability_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a7574-87a8-47e6-abc0-bb839fd2f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 472\n",
      "    Root location: /dev/shm/data/synth/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:08<00:00, 55.28it/s]\n"
     ]
    }
   ],
   "source": [
    "emb = get_embeddings(\"../data/synth/\", n_classes=5, batch_size=1, gpus=1)\n",
    "with open(\"../data/synth_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af743b3b-a536-404f-abec-1f0bc5d9ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 40\n",
      "    Root location: /dev/shm/data/perf/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n",
      "Total: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.99it/s]\n"
     ]
    }
   ],
   "source": [
    "emb = get_embeddings(\"../data/perf/\", n_classes=4, batch_size=1, gpus=1)\n",
    "with open(\"../data/perf_emb.pkl\", \"bw\") as f:\n",
    "    pickle.dump(emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38a627-834d-41df-a092-daf6e2d0f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
