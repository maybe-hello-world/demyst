{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2615c815-0cd3-4aeb-aaf8-c886d4e9966b",
   "metadata": {},
   "source": [
    "## netFound embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f50efb-3a7c-4463-a25b-478269b90520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kell/network-data-representation/src/train\n"
     ]
    }
   ],
   "source": [
    "%cd ../models/netFound/src/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4412e3f-e783-4e26-b991-bfe2fe659008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/k/kell/common_m4629/environments/netfound/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "from NetFoundModels import NetFoundLanguageModelling, NetfoundFinetuningModel, NetFoundBase\n",
    "from NetfoundConfig import NetFoundLarge\n",
    "from NetfoundTokenizer import NetFoundTokenizer\n",
    "from NetFoundDataCollator import SimpleDataCollator\n",
    "from NetFoundTrainer import NetfoundTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import threading\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14f056-dec9-437f-9c28-105cc3db685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:4815] 2025-04-28 17:33:48,537 >> Some weights of NetfoundFinetuningModel were not initialized from the model checkpoint at /dev/shm/data/netfound_checkpoint and are newly initialized: ['classifier.bias', 'classifier.weight', 'hiddenLayer.bias', 'hiddenLayer.weight', 'hiddenLayer2.bias', 'hiddenLayer2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def load_model(path: str):\n",
    "    config = NetFoundLarge()\n",
    "    return NetfoundFinetuningModel.from_pretrained(path, config=config, ignore_mismatched_sizes=True).to(\"cpu\")\n",
    "\n",
    "model = load_model(\"../models/netFound/netfound_checkpoint\")\n",
    "models = {}\n",
    "for i in range(4):\n",
    "    models[i] = copy.deepcopy(model)\n",
    "    models[i].to(f\"cuda:{i}\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35633488-9e9f-4dd1-a4b9-d3e53233d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, batch_size = 32):\n",
    "    tdataset = load_dataset(\"arrow\", data_dir=path, split=\"train\", cache_dir=\"/tmp/tmp\", streaming=False)\n",
    "    total_bursts_train = [0] * len(tdataset)\n",
    "    tdataset = tdataset.add_column(\"total_bursts\", total_bursts_train)\n",
    "    \n",
    "    config = NetFoundLarge()\n",
    "    config.pretraining = True\n",
    "    tokenizer = NetFoundTokenizer(config=config)\n",
    "    tokenizer.raw_labels = True\n",
    "    \n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples)\n",
    "\n",
    "    tdataset = tdataset.map(preprocess_function, batched=True, num_proc=110, load_from_cache_file=True)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        tdataset.remove_columns(['burst_tokens', 'directions', 'counts']),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=8,\n",
    "        prefetch_factor=2,\n",
    "        collate_fn=SimpleDataCollator(config.max_burst_length),\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return tdataset, data_loader\n",
    "\n",
    "def encode(batch, model):\n",
    "    with torch.no_grad():\n",
    "        batch['position_ids'] = torch.arange(\n",
    "                batch['input_ids'].size(1),\n",
    "                device=batch['input_ids'].device\n",
    "            ).unsqueeze(0).expand(batch['input_ids'].size(0), -1)\n",
    "\n",
    "        output = model.base_transformer(\n",
    "            input_ids=batch['input_ids'].to(model.device),\n",
    "            attention_mask=batch['attention_mask'].to(model.device),\n",
    "            position_ids=batch['position_ids'].to(model.device),\n",
    "            direction=batch['direction'].to(model.device),\n",
    "            iats=batch['iats'].to(model.device),\n",
    "            bytes=batch['bytes'].to(model.device),\n",
    "            return_dict=True,\n",
    "            pkt_count=batch['pkt_count'].to(model.device),\n",
    "            protocol=batch['protocol'].to(model.device),\n",
    "        ).last_hidden_state\n",
    "        return torch.mean(output, 1).cpu(), batch[\"labels\"]\n",
    "\n",
    "def encode_and_append(batch, model, result_list, i):\n",
    "    with torch.no_grad():\n",
    "        result_list.append(encode(batch, model))\n",
    "\n",
    "def get_embeddings(datafolder, models, batch_size=64, limit = 10**30, gpus=4):\n",
    "    _, dataloader = load_data(datafolder, batch_size=batch_size)\n",
    "    print(f\"Total: {len(dataloader)}\")\n",
    "    \n",
    "    counter = 0\n",
    "    result_embeddings = []\n",
    "    result_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        iterator = iter(dataloader)\n",
    "        try:\n",
    "            for y in tqdm(range(0, min(len(dataloader) // gpus, limit))):\n",
    "                emb = defaultdict(list)\n",
    "                batches = [next(iterator) for i in range(gpus)]\n",
    "                threads = []\n",
    "                for i in range(gpus):\n",
    "                    t = threading.Thread(target=encode_and_append, args=(batches[i], models[i], emb[i], i))\n",
    "                    t.start()\n",
    "                    threads.append(t)\n",
    "                for t in threads:\n",
    "                    t.join()\n",
    "                del batches\n",
    "                result_embeddings.extend([emb[i][0][0] for i in emb])\n",
    "                for i in emb:\n",
    "                    result_filenames.extend(emb[i][0][1])\n",
    "        except StopIteration:\n",
    "            print(\"finished\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return torch.cat(result_embeddings), result_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccfc12a-033b-4440-bdfe-507b02a3b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"synth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b2e07-2197-43c8-b2ec-2542ef967ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 472 examples [00:00, 4216.95 examples/s]\n",
      "Map (num_proc=110): 100%|██████████| 472/472 [00:00<00:00, 576.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/k/kell/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:1172: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "100%|██████████| 472/472 [00:34<00:00, 13.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    embeddings = get_embeddings(f\"../data/{label}\", models, batch_size=1, gpus=1)\n",
    "    with open(f\"../data/{label}_emb.pkl\", \"bw\") as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e71dbb-27bb-4cec-a792-47f1f4680ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netfound",
   "language": "python",
   "name": "netfound"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
