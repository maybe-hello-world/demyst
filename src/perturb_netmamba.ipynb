{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d772e0-d6e6-4280-8e69-709fe40e2312",
   "metadata": {},
   "source": [
    "# netmamba feature perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7168e4be-c1f1-4432-998b-252ad3b3ef94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define CKA\n",
    "\n",
    "def gram_linear(x):\n",
    "    \"\"\"Compute Gram (kernel) matrix for a linear kernel.\n",
    "\n",
    "    Args:\n",
    "        x: A num_examples x num_features matrix of features.\n",
    "\n",
    "    Returns:\n",
    "        A num_examples x num_examples Gram matrix of examples.\n",
    "    \"\"\"\n",
    "    return x.dot(x.T)\n",
    "\n",
    "\n",
    "def gram_rbf(x, threshold=1.0):\n",
    "    \"\"\"Compute Gram (kernel) matrix for an RBF kernel.\n",
    "\n",
    "    Args:\n",
    "        x: A num_examples x num_features matrix of features.\n",
    "        threshold: Fraction of median Euclidean distance to use as RBF kernel\n",
    "        bandwidth. (This is the heuristic we use in the paper. There are other\n",
    "        possible ways to set the bandwidth; we didn't try them.)\n",
    "\n",
    "    Returns:\n",
    "        A num_examples x num_examples Gram matrix of examples.\n",
    "    \"\"\"\n",
    "    dot_products = x.dot(x.T)\n",
    "    sq_norms = np.diag(dot_products)\n",
    "    sq_distances = -2 * dot_products + sq_norms[:, None] + sq_norms[None, :]\n",
    "    sq_median_distance = np.median(sq_distances)\n",
    "    return np.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))\n",
    "\n",
    "\n",
    "def center_gram(gram, unbiased=False):\n",
    "    \"\"\"Center a symmetric Gram matrix.\n",
    "\n",
    "    This is equvialent to centering the (possibly infinite-dimensional) features\n",
    "    induced by the kernel before computing the Gram matrix.\n",
    "\n",
    "    Args:\n",
    "        gram: A num_examples x num_examples symmetric matrix.\n",
    "        unbiased: Whether to adjust the Gram matrix in order to compute an unbiased\n",
    "        estimate of HSIC. Note that this estimator may be negative.\n",
    "\n",
    "    Returns:\n",
    "        A symmetric matrix with centered columns and rows.\n",
    "    \"\"\"\n",
    "    if not np.allclose(gram, gram.T):\n",
    "        raise ValueError('Input must be a symmetric matrix.')\n",
    "    gram = gram.copy()\n",
    "\n",
    "    if unbiased:\n",
    "        # This formulation of the U-statistic, from Szekely, G. J., & Rizzo, M.\n",
    "        # L. (2014). Partial distance correlation with methods for dissimilarities.\n",
    "        # The Annals of Statistics, 42(6), 2382-2412, seems to be more numerically\n",
    "        # stable than the alternative from Song et al. (2007).\n",
    "        n = gram.shape[0]\n",
    "        np.fill_diagonal(gram, 0)\n",
    "        means = np.sum(gram, 0, dtype=np.float64) / (n - 2)\n",
    "        means -= np.sum(means) / (2 * (n - 1))\n",
    "        gram -= means[:, None]\n",
    "        gram -= means[None, :]\n",
    "        np.fill_diagonal(gram, 0)\n",
    "    else:\n",
    "        means = np.mean(gram, 0, dtype=np.float64)\n",
    "        means -= np.mean(means) / 2\n",
    "        gram -= means[:, None]\n",
    "        gram -= means[None, :]\n",
    "\n",
    "    return gram\n",
    "\n",
    "\n",
    "def cka(gram_x, gram_y, debiased=False):\n",
    "    \"\"\"Compute CKA.\n",
    "\n",
    "    Args:\n",
    "        gram_x: A num_examples x num_examples Gram matrix.\n",
    "        gram_y: A num_examples x num_examples Gram matrix.\n",
    "        debiased: Use unbiased estimator of HSIC. CKA may still be biased.\n",
    "\n",
    "    Returns:\n",
    "        The value of CKA between X and Y.\n",
    "    \"\"\"\n",
    "    gram_x = center_gram(gram_x, unbiased=debiased)\n",
    "    gram_y = center_gram(gram_y, unbiased=debiased)\n",
    "\n",
    "    # Note: To obtain HSIC, this should be divided by (n-1)**2 (biased variant) or\n",
    "    # n*(n-3) (unbiased variant), but this cancels for CKA.\n",
    "    scaled_hsic = gram_x.ravel().dot(gram_y.ravel())\n",
    "\n",
    "    normalization_x = np.linalg.norm(gram_x)\n",
    "    normalization_y = np.linalg.norm(gram_y)\n",
    "    return scaled_hsic / (normalization_x * normalization_y)\n",
    "\n",
    "\n",
    "def _debiased_dot_product_similarity_helper(\n",
    "    xty, sum_squared_rows_x, sum_squared_rows_y, squared_norm_x, squared_norm_y,\n",
    "    n):\n",
    "  \"\"\"Helper for computing debiased dot product similarity (i.e. linear HSIC).\"\"\"\n",
    "  # This formula can be derived by manipulating the unbiased estimator from\n",
    "  # Song et al. (2007).\n",
    "  return (\n",
    "      xty - n / (n - 2.) * sum_squared_rows_x.dot(sum_squared_rows_y)\n",
    "      + squared_norm_x * squared_norm_y / ((n - 1) * (n - 2)))\n",
    "\n",
    "\n",
    "def feature_space_linear_cka(features_x, features_y, debiased=False):\n",
    "    \"\"\"Compute CKA with a linear kernel, in feature space.\n",
    "\n",
    "    This is typically faster than computing the Gram matrix when there are fewer\n",
    "    features than examples.\n",
    "\n",
    "    Args:\n",
    "        features_x: A num_examples x num_features matrix of features.\n",
    "        features_y: A num_examples x num_features matrix of features.\n",
    "        debiased: Use unbiased estimator of dot product similarity. CKA may still be\n",
    "        biased. Note that this estimator may be negative.\n",
    "\n",
    "    Returns:\n",
    "        The value of CKA between X and Y.\n",
    "    \"\"\"\n",
    "    features_x = features_x - np.mean(features_x, 0, keepdims=True)\n",
    "    features_y = features_y - np.mean(features_y, 0, keepdims=True)\n",
    "\n",
    "    dot_product_similarity = np.linalg.norm(features_x.T.dot(features_y)) ** 2\n",
    "    normalization_x = np.linalg.norm(features_x.T.dot(features_x))\n",
    "    normalization_y = np.linalg.norm(features_y.T.dot(features_y))\n",
    "\n",
    "    if debiased:\n",
    "        n = features_x.shape[0]\n",
    "        # Equivalent to np.sum(features_x ** 2, 1) but avoids an intermediate array.\n",
    "        sum_squared_rows_x = np.einsum('ij,ij->i', features_x, features_x)\n",
    "        sum_squared_rows_y = np.einsum('ij,ij->i', features_y, features_y)\n",
    "        squared_norm_x = np.sum(sum_squared_rows_x)\n",
    "        squared_norm_y = np.sum(sum_squared_rows_y)\n",
    "\n",
    "        dot_product_similarity = _debiased_dot_product_similarity_helper(\n",
    "            dot_product_similarity, sum_squared_rows_x, sum_squared_rows_y,\n",
    "            squared_norm_x, squared_norm_y, n)\n",
    "        normalization_x = np.sqrt(_debiased_dot_product_similarity_helper(\n",
    "            normalization_x ** 2, sum_squared_rows_x, sum_squared_rows_x,\n",
    "            squared_norm_x, squared_norm_x, n))\n",
    "        normalization_y = np.sqrt(_debiased_dot_product_similarity_helper(\n",
    "            normalization_y ** 2, sum_squared_rows_y, sum_squared_rows_y,\n",
    "            squared_norm_y, squared_norm_y, n))\n",
    "\n",
    "    return dot_product_similarity / (normalization_x * normalization_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf0f01-c4a7-4867-be1a-3e2bda13e3d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/k/kell/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kell/demystifying/NetMamba/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/k/kell/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# change folder to netmamba src\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import models_net_mamba\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from timm.models.layers import trunc_normal_\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "import pickle\n",
    "\n",
    "os.environ['PATH'] = '/sbin:' + os.environ.get('PATH', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874eef3-72e2-469a-b78b-3442c3a4c46f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_loader(data_path, batch_size=1):\n",
    "    mean = [0.5]\n",
    "    std = [0.5]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, sampler=sampler,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=1\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def get_model():\n",
    "    model = models_net_mamba.__dict__['net_mamba_classifier'](\n",
    "        num_classes=2,\n",
    "        drop_path_rate=0,\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load('../models/NetMamba/pre-train.pth', map_location='cpu')\n",
    "    checkpoint_model = checkpoint['model']\n",
    "    state_dict = model.state_dict()\n",
    "    for k in ['head.weight', 'head.bias']:\n",
    "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "    \n",
    "    # interpolate position embedding\n",
    "    interpolate_pos_embed(model, checkpoint_model)\n",
    "    \n",
    "    # load pre-trained model\n",
    "    msg = model.load_state_dict(checkpoint_model, strict=False)\n",
    "    print(msg)\n",
    "    \n",
    "    # manually initialize fc layer\n",
    "    trunc_normal_(model.head.weight, std=2e-5)\n",
    "    model = model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46198fdd-7138-4448-9344-5d51915aba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096\n",
    "LIMIT = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cbf81-5a56-4b15-b9b4-6cf9e0549d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['mask_token', 'decoder_pos_embed', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.mixer.A_log', 'decoder_blocks.0.mixer.D', 'decoder_blocks.0.mixer.in_proj.weight', 'decoder_blocks.0.mixer.conv1d.weight', 'decoder_blocks.0.mixer.conv1d.bias', 'decoder_blocks.0.mixer.x_proj.weight', 'decoder_blocks.0.mixer.dt_proj.weight', 'decoder_blocks.0.mixer.dt_proj.bias', 'decoder_blocks.0.mixer.out_proj.weight', 'decoder_blocks.0.norm.weight', 'decoder_blocks.1.mixer.A_log', 'decoder_blocks.1.mixer.D', 'decoder_blocks.1.mixer.in_proj.weight', 'decoder_blocks.1.mixer.conv1d.weight', 'decoder_blocks.1.mixer.conv1d.bias', 'decoder_blocks.1.mixer.x_proj.weight', 'decoder_blocks.1.mixer.dt_proj.weight', 'decoder_blocks.1.mixer.dt_proj.bias', 'decoder_blocks.1.mixer.out_proj.weight', 'decoder_blocks.1.norm.weight', 'decoder_norm_f.weight', 'decoder_pred.weight', 'decoder_pred.bias'])\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_loader(\"../data/netmamba/array_sampled\", batch_size=BATCH_SIZE)\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929837b7-44fa-456a-be87-14b92501e68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata layout is the same as YaTC\\nheader in YaTC is 80 floats:\\n48:56 are seq\\n56:64 are ack\\n6:8 is total length\\n16:18 is TTL\\nflags are 12, 20, 23\\n68:76 is WSize\\n\\nthen we have 240 floats of payload\\ntotal 320 floats for a single packet\\ntotal 5 packet = 1600 floats\\nreshaped to 40, 40 getting a single image\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data layout is the same as YaTC\n",
    "header in YaTC is 80 floats:\n",
    "48:56 are seq\n",
    "56:64 are ack\n",
    "6:8 is total length\n",
    "16:18 is TTL\n",
    "flags are 12, 20, 23\n",
    "68:76 is WSize\n",
    "\n",
    "then we have 240 floats of payload\n",
    "total 320 floats for a single packet\n",
    "total 5 packet = 1600 floats\n",
    "reshaped to 40, 40 getting a single image\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b57464-410a-4790-bf87-c9eb175d142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_mask(packet_mask: np.ndarray):\n",
    "    \"320 floats to 1600 and reshape\"\n",
    "    assert packet_mask.shape == (320,)\n",
    "    return np.reshape(np.tile(packet_mask, 5), (40, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2976cff5-c5eb-4daf-add1-c5c90fc85fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(batch, model):\n",
    "    batch = batch.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        return model.forward_encoder(batch, mask_ratio=0.0, if_mask=False)[:, -1, :].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241a62cf-0cfb-418c-89a6-54810c168adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(dataset, model, packet_mask, random=False):\n",
    "    \"takes dataset, model, and binary mask for indices allowed for perturbation, generates random noise tensor with respect to the mask, applies it to the dataset, gets embeddings, returns resulting noise tensor and embeddings\"\n",
    "    embeddings = []\n",
    "    noises = []\n",
    "    total = 0\n",
    "    sims = []\n",
    "    mask_np = repeat_mask(packet_mask)\n",
    "    for batch, _ in tqdm(dataset):\n",
    "        orig_input = batch.clone()\n",
    "        B, C, H, W = batch.size()\n",
    "        noise = torch.empty_like(batch)\n",
    "\n",
    "        if not random:\n",
    "            for h in range(H):\n",
    "                for w in range(W):\n",
    "                    perm = torch.randperm(B)\n",
    "                    noise[:, :, h, w] = batch[perm, :, h, w]\n",
    "        else:\n",
    "            noise = torch.rand((batch.size(0), 1, 40, 40)) * 2 - 1  # from -1 to +1\n",
    "\n",
    "        mask_torch = torch.from_numpy(mask_np).bool().unsqueeze(0).unsqueeze(0).cpu()  # (1, 1, 40, 40)\n",
    "        mask_torch = mask_torch.repeat(batch.size(0), 1, 1, 1)\n",
    "        batch[mask_torch] = noise[mask_torch]\n",
    "        perturbed_features = encode(batch, model)\n",
    "        embeddings.append(perturbed_features)\n",
    "        sims.append((batch == orig_input).float().mean().item())\n",
    "        total += batch.size(0)\n",
    "        if total > LIMIT:\n",
    "            break\n",
    "        \n",
    "    print(f\"Similarity: {np.mean(sims)}\")\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return embeddings    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0b164b-be25-4fc6-81d4-7a54fd7fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _perturb(packet_mask, random=False):\n",
    "    return get_embedding(dataloader, model, packet_mask, random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc079a9e-1a31-4152-997a-f7f51c152145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import torch\n",
    "\n",
    "# define correlation calculation function\n",
    "\n",
    "# def calculate_correlation(emb_original: torch.Tensor, noise: torch.Tensor, emb_perturbed: torch.Tensor) -> np.ndarray:\n",
    "#     '''accepts original embedding, noise, and embedding after perturbation, and calculates similarity correlation between noise and each dimension of the perturbation result'''\n",
    "#     emb_diff = emb_perturbed - emb_original\n",
    "\n",
    "#     cos_sim = torch.nn.functional.cosine_similarity(emb_perturbed, emb_original).mean()\n",
    "#     l2_dist = torch.cdist(emb_perturbed, emb_original, p=2).mean()\n",
    "\n",
    "#     emb_diff_np = emb_diff.detach().cpu().numpy()\n",
    "#     noise_np = noise.detach().cpu().numpy()\n",
    "#     noise_np = np.reshape(noise_np, (noise_np.shape[0], -1))\n",
    "#     noise_np = noise_np[:, noise_np.any(axis=0)]  # keep only non zero noise columns effectively removing masked out columns \n",
    "\n",
    "#     n_dims = emb_diff_np.shape[1]\n",
    "#     cka_scores = np.zeros(n_dims)\n",
    "    \n",
    "#     for d in tqdm(range(n_dims)):\n",
    "#         # extract the nth column as a 2D array\n",
    "#         feature_column = emb_diff_np[:, d].reshape(-1, 1)\n",
    "#         cka_scores[d] = feature_space_linear_cka(noise_np, feature_column)\n",
    "\n",
    "#     return cos_sim, l2_dist, cka_scores\n",
    "\n",
    "def calculate_correlation(emb_original: torch.Tensor, emb_perturbed: torch.Tensor) -> float:\n",
    "    # simplified\n",
    "    return torch.nn.functional.cosine_similarity(emb_perturbed, emb_original).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76517369-4e5a-4f1c-8232-dcef3e71ea20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/331 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 39.38 GiB of which 2.22 GiB is free. Process 713985 has 12.41 GiB memory in use. Process 720975 has 13.24 GiB memory in use. Including non-PyTorch memory, this process has 11.49 GiB memory in use. Of the allocated memory 9.44 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# original embeddings\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m320\u001b[39m)  \u001b[38;5;66;03m# zero mask\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m original_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43m_perturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36m_perturb\u001b[0;34m(packet_mask, random)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_perturb\u001b[39m(packet_mask, random\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(dataset, model, packet_mask, random)\u001b[0m\n\u001b[1;32m     22\u001b[0m mask_torch \u001b[38;5;241m=\u001b[39m mask_torch\u001b[38;5;241m.\u001b[39mrepeat(batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m batch[mask_torch] \u001b[38;5;241m=\u001b[39m noise[mask_torch]\n\u001b[0;32m---> 24\u001b[0m perturbed_features \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mappend(perturbed_features)\n\u001b[1;32m     26\u001b[0m sims\u001b[38;5;241m.\u001b[39mappend((batch \u001b[38;5;241m==\u001b[39m orig_input)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(batch, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/NetMamba/src/models_net_mamba.py:224\u001b[0m, in \u001b[0;36mNetMamba.forward_encoder\u001b[0;34m(self, x, mask_ratio, if_mask)\u001b[0m\n\u001b[1;32m    222\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 224\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m fused_add_norm_fn \u001b[38;5;241m=\u001b[39m rms_norm_fn\n\u001b[1;32m    226\u001b[0m x \u001b[38;5;241m=\u001b[39m fused_add_norm_fn(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(hidden_states),\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     residual_in_fp32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    234\u001b[0m )\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/NetMamba/src/models_mamba.py:94\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, hidden_states, residual, inference_params)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m         hidden_states, residual \u001b[38;5;241m=\u001b[39m fused_add_norm_fn(\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(hidden_states),\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m             eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m     93\u001b[0m         )    \n\u001b[0;32m---> 94\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states, residual\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/NetMamba/mamba-1p1p1/mamba_ssm/modules/mamba_simple.py:249\u001b[0m, in \u001b[0;36mMamba.forward\u001b[0;34m(self, hidden_states, inference_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(rearrange(out \u001b[38;5;241m+\u001b[39m out_b\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb d l -> b l d\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmamba_inner_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mxz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# input-dependent B\u001b[39;49;00m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# input-dependent C\u001b[39;49;00m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelta_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelta_softplus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     x, z \u001b[38;5;241m=\u001b[39m xz\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/NetMamba/mamba-1p1p1/mamba_ssm/ops/selective_scan_interface.py:612\u001b[0m, in \u001b[0;36mmamba_inner_fn\u001b[0;34m(xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight, out_proj_weight, out_proj_bias, A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmamba_inner_fn\u001b[39m(\n\u001b[1;32m    607\u001b[0m     xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n\u001b[1;32m    608\u001b[0m     out_proj_weight, out_proj_bias,\n\u001b[1;32m    609\u001b[0m     A, B\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, B_proj_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    610\u001b[0m     C_proj_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_softplus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    611\u001b[0m ):\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMambaInnerFn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_proj_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_proj_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_softplus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/scratch/demystifying/netmambaenv/lib/python3.10/site-packages/torch/cuda/amp/autocast_mode.py:113\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n",
      "File \u001b[0;32m/pscratch/sd/k/kell/demystifying/NetMamba/mamba-1p1p1/mamba_ssm/ops/selective_scan_interface.py:318\u001b[0m, in \u001b[0;36mMambaInnerFn.forward\u001b[0;34m(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight, out_proj_weight, out_proj_bias, A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus, checkpoint_lvl)\u001b[0m\n\u001b[1;32m    316\u001b[0m x, z \u001b[38;5;241m=\u001b[39m xz\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    317\u001b[0m conv1d_bias \u001b[38;5;241m=\u001b[39m conv1d_bias\u001b[38;5;241m.\u001b[39mcontiguous() \u001b[38;5;28;01mif\u001b[39;00m conv1d_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m conv1d_out \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_conv1d_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcausal_conv1d_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# We're being very careful here about the layout, to avoid extra transposes.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# We want delta to have d as the slowest moving dimension\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# and L as the fastest moving dimension, since those are what the ssm_scan kernel expects.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m x_dbl \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(rearrange(conv1d_out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb d l -> (b l) d\u001b[39m\u001b[38;5;124m'\u001b[39m), x_proj_weight)  \u001b[38;5;66;03m# (bl d)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.13 GiB. GPU 0 has a total capacty of 39.38 GiB of which 2.22 GiB is free. Process 713985 has 12.41 GiB memory in use. Process 720975 has 13.24 GiB memory in use. Including non-PyTorch memory, this process has 11.49 GiB memory in use. Of the allocated memory 9.44 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# original embeddings\n",
    "mask = np.array([0] * 320)  # zero mask\n",
    "original_embeddings = _perturb(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03e1c4-46ee-4b06-9b1a-257cfb71b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a00a7-ea2d-4405-a476-5c9123a1fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(mask):\n",
    "    new_emb, new_noise = _perturb(mask)\n",
    "    cos_sim, l2_dist, correlation = calculate_correlation(original_embeddings, new_noise, new_emb)\n",
    "    top5_sim = np.argsort(correlation)[-5:]\n",
    "    print(f\"Cos sim: {cos_sim}\")\n",
    "    print(f\"L2 distance: {l2_dist}\")\n",
    "    print(f\"Average similarity: {np.mean(correlation)}\")\n",
    "    print(f\"Top 5 indices: {top5_sim[::-1]}\")\n",
    "    print(f\"Top 5 similarity values: {correlation[top5_sim][::-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3baad3-7d42-4063-89d4-ad4fc1ff2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified\n",
    "def calculate_similarity(mask):\n",
    "    new_emb = _perturb(mask, random=True)\n",
    "    cos_sim = calculate_correlation(original_embeddings, new_emb)\n",
    "    print(f\"Cos sim for random source perturbation: {cos_sim}\")\n",
    "\n",
    "    new_emb = _perturb(mask)\n",
    "    cos_sim = calculate_correlation(original_embeddings, new_emb)\n",
    "    print(f\"Cos sim for reordered perturbation: {cos_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9917e2-7212-4b2d-aeb6-427170a538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload\n",
    "calculate_similarity(np.array([0] * 80 + [1] * 240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149d3c9-0dac-4899-b839-094c77c67ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ/ACK\n",
    "# 48:56 are seq\n",
    "# 56:64 are ack\n",
    "calculate_similarity(np.array([0] * 48 + [1] * 16 + [0] * 16 + [0] * 240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738885f0-c439-47f3-b362-ece1ab7e16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP total length\n",
    "# 6:8 is total length\n",
    "calculate_similarity(np.array([0] * 6 + [1] * 2 + [0] * (72 + 240)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655ef79-319a-404c-aa74-f65ef6d11eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP TTL\n",
    "# 16:18 is TTL\n",
    "calculate_similarity(np.array([0] * 16 + [1] * 2 + [0] * (62 + 240)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b9432-e7c5-415d-b020-d5295c93247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP Flags\n",
    "# flags are 12, 20, 23\n",
    "calculate_similarity(np.array(\n",
    "    [0] * 12 + [1] * 1 + \n",
    "    [0] * 7 + [1] * 1 + \n",
    "    [0] * 2 + [1] * 1 +\n",
    "    [0] * (56 + 240)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982fd6d-2da7-4354-a0d9-6d59e305010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP WSize (68:76)\n",
    "calculate_similarity(np.array([0] * 68 + [1] * 8 + [0] * (4 + 240)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7075ef-afaf-4e13-bfe0-7d492935f44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netmamba",
   "language": "python",
   "name": "netmamba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
